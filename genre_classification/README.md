# Rap Genre Classification

## Problem Definition
Given a set of $n$ rap songs ![songs](http://latex.codecogs.com/gif.latex?%24S%3D%5Cleft%5C%7BS_1%2CS_2%2C...%2CS_n%5Cright%5C%7D%24), and a set of ![nb of genre](http://latex.codecogs.com/gif.latex?m) genre labels ![genre labels](http://latex.codecogs.com/gif.latex?%24%5Cmathcal%7BG%7D%3D%5Cleft%5C%7Bg_1%2Cg_2%2C...%2Cg_m%5Cright%5C%7D%24), the aim is to map a set of ![nb of labels](http://latex.codecogs.com/gif.latex?k) labels ![labels](http://latex.codecogs.com/gif.latex?%24%5Cmathcal%7BL%7D%3D%5Cleft%5C%7B%5Cell_1%2C%5Cell_2%2C...%2C%5Cell_k%5Cright%5C%7D%28%5Cmathcal%7BL%7D%5Csubseteq%20%5Cmathcal%7BG%7D%29%24) with ![s](http://latex.codecogs.com/gif.latex?%24S_%7Bi%281%5Cleq%20i%5Cleq%20n%29%7D%24).
## Dataset
Due to copyright problems and the absence of researches on rap genre classification, we create a dataset including 10,167 songs and 9 genres. First, we divide rappers into 9 popular genres ![genres](http://latex.codecogs.com/gif.latex?%24%5Cmathcal%7BG%7D%3D%5Cleft%5C%7Bg_1%2Cg_1%2C...%2Cg_9%5Cright%5C%7D%24) according to [Wikipedia](https://en.wikipedia.org/wiki/Category:Hip_hop_musicians_by_genre). The genre labels of a rap song ![si](http://latex.codecogs.com/gif.latex?%24S_i%24) are tagged by its artist set ![A](http://latex.codecogs.com/gif.latex?%24A%3D%5Cleft%5C%7Ba_%7Bi%2C1%7D%2Ca_%7Bi%2C2%7D%2C...%2Ca_%7Bi%2C%20n%7D%5Cright%5C%7D%24) (![n](http://latex.codecogs.com/gif.latex?n) is the number of the ![ith](http://latex.codecogs.com/gif.latex?i_%7Bth%7D) song's artists). ![gj](http://latex.codecogs.com/gif.latex?g_%7Bj%281%5Cleq%20j%5Cleq%209%29%7D) is added into the ![ith](http://latex.codecogs.com/gif.latex?i_%7Bth%7D) song's label set only if ![aik](http://latex.codecogs.com/gif.latex?a_%7Bi%2Ck%281%5Cleq%20k%5Cleq%20n%29%7D%20%5Cin%20g_j). Essentially Speaking, the rap genre classification task is a multi-label classification task.
## Experiment Setting
For the semantic representation ![s](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20s), we just use the whole song as the input of the semantic section.
For rhyming features, we take 3 steps. First, we regard a whole rap song as a prosodic block and compute its prosodic vector ![l0](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_0%7D). In this step, we obtain the C-Line vector of a song. Second, we extract all the odd lines and computing their prosodic vector ![lodd](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_%7Bodd%7D%7D). At the same time, we conduct the same procedure on the even lines and obtain ![leven](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_%7Beven%7D%7D). We obtain the Skip-Line vector by adding ![lodd](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_%7Bodd%7D%7D) and ![leven](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_%7Beven%7D%7D). Finally, we feed ![l0](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_0%7D) and ![l1](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Bl_1%7D) into the proposed prosodic embedding model Pho2vec, and obtain the prosodic representation of a rap song ![r](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Br%7D).
The final song vector ![mu](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%5Cmu) is generated by feeding ![s](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20s) and ![r](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7Br%7D) into the union-training module.
We use all methods to produce a 9 dimensional variable ![y](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20y) through a same sigmoid network. If ![yj](http://latex.codecogs.com/gif.latex?y_%7Bj%281%5Cleq%20j%5Cle%209%29%7D%5Cle%20i), we set ![yj0](\hat y_{j(1\leq j\le 9)}=0), otherwise,  ![yj1](http://latex.codecogs.com/gif.latex?%5Chat%20y_%7Bj%281%5Cleq%20j%5Cle%209%29%7D%3D1). ![i](http://latex.codecogs.com/gif.latex?i) is a stated parameter. ![yhat](http://latex.codecogs.com/gif.latex?%5Cboldsymbol%20%7B%5Chat%20y%7D%3D%5Cleft%5Clbrace%20%5Chat%20y_0%2C%5Chat%20y_1%2C%20...%2C%5Chat%20y_9%20%5Cright%5Crbrace) is the predicted label set.
## Files
./Doc2vec, ./Rhyme2vec_whole, ./HAN./ RhymeAPP and ./attaerl contain input data for corresponding models. ./label contains training and testing labels for the classifier.
